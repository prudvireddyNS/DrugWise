{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TFAutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "text = tokenizer.encode('Hi', return_tensors='pt')\n",
    "output = model.generate(text, max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi. I'm sorry, but I'm not sure if you're aware of this. I'm not sure if you're aware of this.\\n\\nI'm sorry, but I'm not sure if you're aware of this. I'm not sure if you're aware of this.\\n\\nI'm sorry, but I'm not sure if you're aware of this. I'm not sure if you're aware of this.\\n\\nI'm sorry, but I'm not sure if you\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(text, model, tokenizer, max_input_tokens = 100, max_output_tokens = 1000):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Move the model to the appropriate device\n",
    "    model.to(device)\n",
    "    input_ids = tokenizer.encode(\n",
    "        text,\n",
    "        return_tensors='pt',\n",
    "        truncation=True,\n",
    "        max_length = max_input_tokens\n",
    "    ).to(device)\n",
    "\n",
    "    generated_tokens_with_prompt = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        max_length = max_output_tokens\n",
    "    ).to(device)\n",
    "\n",
    "    generated_text_with_prompt = tokenizer.batch_decode(generated_tokens_with_prompt, skip_special_tokens=True)\n",
    "\n",
    "    generated_text_answer = generated_text_with_prompt[0][len(text):]\n",
    "\n",
    "    return generated_text_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" it.\\n\\nI'm not sure if I'm going to be able to do it, but I'm going to be able to do it.\\n\\nI'm not sure if I'm going to be able to do it, but I'm going to be able to do it.\\n\\nI'm not sure if I'm going to be able to do it, but I'm going to be able to do it.\\n\\nI'm not sure if I'm going to be able to do it, but I'm going to be able to do it.\\n\\nI'm not sure if I'm going to be able to do it, but I'm going to be able to do it.\\n\\nI'm not sure if I'm going to be able to do it, but I'm going to be able to do it.\\n\\nI'm not sure if I'm going to be able to do it, but I'm going to be able to do it.\\n\\nI'm not sure if I'm going to be able to do it, but I'm going to be able to do it.\\n\\nI'm not sure if I'm going to be able to do it, but I'm going to be able to do it.\\n\\nI'm not sure if I'm going to be able to do it, but I'm going to be able to do it.\\n\\nI'm not sure if I'm going to be able to do it, but I'm going to be able to do it.\\n\\nI'm not sure if I'm going to be able to do it, but I'm going to be able to do it.\\n\\nI'm not sure if I'm going to be able to do it, but I'm going to be able to do it.\\n\\nI'm not sure if I'm going to be able to do it, but I'm going to be able to do it.\\n\\nI'm not sure if I'm going to be able to do it, but I'm going to be able to do it.\\n\\nI'm not sure if I'm going to be able to do it, but I'm going to be able to do it.\\n\\nI'm not sure if I'm going to be able to do it, but I'm going to be able to do it.\\n\\nI'm not sure if I'm going to be able to do it, but I'm going to be able to do it.\\n\\nI'm not sure if I'm going to be able to do it, but I'm going to be able to do it.\\n\\nI'm not sure if I'm going to be able to do it, but I'm going to be able to do it.\\n\\nI'm not sure if I'm going to be able to do it, but I'm going to be able to do it.\\n\\nI'm not sure if I'm going to be able to do it, but I'm going to be able to do it.\\n\\nI'm not sure if I'm going to be able to do it, but I'm going to be able to do it.\\n\\nI'm not sure if I'm going to be able to do it, but I'm going to be able to do it.\\n\\nI'm not sure if I'm going to be able to do it, but I'm going to be able to do it.\\n\\nI'm not sure if I'm going to be able to do it, but I'm going to be able to do it.\\n\\nI'm not sure if I'm going to be able to do it, but I'm going to be able to do it.\\n\\nI'm not sure if I'm going to be able to do it, but I'm going to be able to do it.\\n\\nI'm not sure if I'm going to be able to do it, but I'm going to be able to do it.\\n\\nI'm not sure if I'm going to be able to do it, but I'm going to be able to do it.\\n\\nI'm not sure if I'm going to be able to do it, but I'm going to be able to do it.\\n\\nI'm not sure if I'm going to be able to do it, but I'm going to be able to do it.\\n\\nI'm not sure if I'm going to be able to do it, but I'm going to be able to do it.\\n\\nI'm not sure if I'm going to be able to do it, but I'm going to be able to do it.\\n\\nI'm not sure if I'm going to be able to do it, but I'm going to be able to do it.\\n\\nI'm not sure if I'm going to be able to do\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference('let me cook',model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
